{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOROA5EwOu+7N03o7cBLc1c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SomeiLam/langchain-example/blob/main/LangChain_q%26a_over_documents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qX1Fjogp6XnB"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install langchain_community\n",
        "!pip install -U langchain-openai\n",
        "!pip install docarray"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']\n",
        "llm_model = \"gpt-3.5-turbo-0301\""
      ],
      "metadata": {
        "id": "6CKjxZpX6iwp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.vectorstores import DocArrayInMemorySearch\n",
        "from IPython.display import display, Markdown\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "lDB60kGQ6n1u"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = 'OutdoorClothingCatalog_1000.csv'\n",
        "loader = CSVLoader(file_path=file)"
      ],
      "metadata": {
        "id": "Df5vN_8r7U3C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embedding_model = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "w6EWOuQN7WcD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.vectorstores import DocArrayInMemorySearch\n",
        "\n",
        "index_creator = VectorstoreIndexCreator(\n",
        "    embedding=embedding_model,\n",
        "    vectorstore_cls=DocArrayInMemorySearch,\n",
        ")\n",
        "index = index_creator.from_loaders([loader])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig6nXe_i7blR",
        "outputId": "d2ad29c1-be0e-4a19-d633-498578c433ea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
            "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query =\"Please list all your shirts with sun protection \\\n",
        "in a table in markdown and summarize each one.\""
      ],
      "metadata": {
        "id": "3XmSS1qA8hbZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_replacement_model = OpenAI(temperature=0,\n",
        "                               model='gpt-3.5-turbo-instruct')\n",
        "\n",
        "response = index.query(query,\n",
        "                       llm = llm_replacement_model)"
      ],
      "metadata": {
        "id": "be4txO5W8oL5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "FQYDDt8083b-",
        "outputId": "1d1ff1c8-0766-41b3-c749-16a164df473e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\n| Name | Description | Sun Protection Rating |\n| --- | --- | --- |\n| Men's Tropical Plaid Short-Sleeve Shirt | Made of 100% polyester, UPF 50+ rating, wrinkle-resistant, front and back cape venting, two front bellows pockets | SPF 50+, blocks 98% of harmful UV rays |\n| Men's Plaid Tropic Shirt, Short-Sleeve | Made of 52% polyester and 48% nylon, UPF 50+ rating, SunSmart technology, wrinkle-free, front and back cape venting, two front bellows pockets | SPF 50+, blocks 98% of harmful UV rays |\n| Men's TropicVibe Shirt, Short-Sleeve | Made of 71% nylon and 29% polyester, UPF 50+ rating, front and back cape venting, two front bellows pockets | SPF 50+, blocks 98% of harmful UV rays |\n| Sun Shield Shirt | Made of 78% nylon and 22% Lycra Xtra Life fiber, UPF 50+ rating, moisture-wicking, abrasion-resistant, fits over swimsuit | SPF 50+, blocks 98% of harmful UV rays |"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step by Step"
      ],
      "metadata": {
        "id": "0czSfGDd88Vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import CSVLoader\n",
        "loader = CSVLoader(file_path=file)"
      ],
      "metadata": {
        "id": "DfvadI3v8-yt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "osclnErW9Ao1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-PuK6-69Btl",
        "outputId": "79c63c4a-0180-4755-fdbb-c675a1bf3bc0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'OutdoorClothingCatalog_1000.csv', 'row': 0}, page_content=\": 0\\nname: Women's Campside Oxfords\\ndescription: This ultracomfortable lace-to-toe Oxford boasts a super-soft canvas, thick cushioning, and quality construction for a broken-in feel from the first time you put them on. \\n\\nSize & Fit: Order regular shoe size. For half sizes not offered, order up to next whole size. \\n\\nSpecs: Approx. weight: 1 lb.1 oz. per pair. \\n\\nConstruction: Soft canvas material for a broken-in feel and look. Comfortable EVA innersole with Cleansport NXT® antimicrobial odor control. Vintage hunt, fish and camping motif on innersole. Moderate arch contour of innersole. EVA foam midsole for cushioning and support. Chain-tread-inspired molded rubber outsole with modified chain-tread pattern. Imported. \\n\\nQuestions? Please contact us for any inquiries.\")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "liD1EQL29Dt2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed = embeddings.embed_query(\"Hi my name is Harrison\")"
      ],
      "metadata": {
        "id": "i4oTUg_W9Ft1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(embed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SyrNCjy9G_a",
        "outputId": "ac562d14-b2ce-49eb-b05c-6a34fa51774e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embed[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFre2IeM9IhU",
        "outputId": "9400ad85-e891-43e9-98d8-23a36dfb9344"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.02196465528695117, 0.006758838256223806, -0.018249490165056663, -0.03923515029463157, -0.014007174091135742]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db = DocArrayInMemorySearch.from_documents(\n",
        "    docs,\n",
        "    embeddings\n",
        ")"
      ],
      "metadata": {
        "id": "llOFuSNT9LyQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Please suggest a shirt with sunblocking\""
      ],
      "metadata": {
        "id": "lE7fi8pW9Ng6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = db.similarity_search(query)"
      ],
      "metadata": {
        "id": "FNHoIchm9Pc_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xURxRZ7S9Rl9",
        "outputId": "09ba0ec4-0b18-47dc-86f7-60cb4b048ad4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwcE138O9Sfb",
        "outputId": "e9d6cd81-666d-4fe5-889c-e73dc140f113"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'OutdoorClothingCatalog_1000.csv', 'row': 255}, page_content=': 255\\nname: Sun Shield Shirt by\\ndescription: \"Block the sun, not the fun – our high-performance sun shirt is guaranteed to protect from harmful UV rays. \\n\\nSize & Fit: Slightly Fitted: Softly shapes the body. Falls at hip.\\n\\nFabric & Care: 78% nylon, 22% Lycra Xtra Life fiber. UPF 50+ rated – the highest rated sun protection possible. Handwash, line dry.\\n\\nAdditional Features: Wicks moisture for quick-drying comfort. Fits comfortably over your favorite swimsuit. Abrasion resistant for season after season of wear. Imported.\\n\\nSun Protection That Won\\'t Wear Off\\nOur high-performance fabric provides SPF 50+ sun protection, blocking 98% of the sun\\'s harmful rays. This fabric is recommended by The Skin Cancer Foundation as an effective UV protectant.')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = db.as_retriever()"
      ],
      "metadata": {
        "id": "c2hUiefe-G-_"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.9)"
      ],
      "metadata": {
        "id": "YWtMlHHm9U2L"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qdocs = \"\".join([docs[i].page_content for i in range(len(docs))])"
      ],
      "metadata": {
        "id": "OveY1TwH9WFR"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(f\"{qdocs} Question: Please list all your \\\n",
        "shirts with sun protection in a table in markdown and summarize each one.\")"
      ],
      "metadata": {
        "id": "qktJ3ElY9YJz"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "2tpwua_k98GW",
        "outputId": "ac3170f9-d0ab-4f6e-8f9f-f35f6d959d48"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "| Name                                | Description                                                                                                                                                                                                                                                                      |\n|-------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Sun Shield Shirt by                 | This high-performance sun shirt is guaranteed to protect from harmful UV rays, with UPF 50+ rated sun protection. Made of 78% nylon and 22% Lycra Xtra Life fiber, it wicks moisture, fits comfortably over swimsuits, and is abrasion resistant.                                                   |\n| Men's Plaid Tropic Shirt, Short-Sleeve | Ultracomfortable sun protection rated UPF 50+, great for fishing and travel. Made of 52% polyester and 48% nylon, this wrinkle-free, moisture-wicking shirt features front and back venting, bellows pockets, and blocks 98% of harmful UV rays.                                   |\n| Men's TropicVibe Shirt, Short-Sleeve   | This sun-protection shirt for men has UPF 50+ coverage, with a traditional fit made of 71% Nylon and 29% Polyester. It is wrinkle-resistant, features front and back venting, bellows pockets, and blocks 98% of harmful UV rays.                                                   |\n| Men's Tropical Plaid Short-Sleeve Shirt | This hot-weather shirt is rated UPF 50+ for superior sun protection, with a traditional fit and made of 100% polyester. It is wrinkle-resistant, features front and back venting, bellows pockets, and blocks 98% of harmful UV rays.                                   |"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_stuff = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "4dkuLON--CWe"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query =  \"Please list all your shirts with sun protection in a table \\\n",
        "in markdown and summarize each one.\""
      ],
      "metadata": {
        "id": "2qP3oWHT-KgX"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = qa_stuff.invoke(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFTkh6m--RS7",
        "outputId": "49215b8c-82fd-4628-ca56-404814981f1e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "0lQR-yxU-VDz",
        "outputId": "8f0387c6-f7ff-4020-de3f-e88fc73d7248"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Sure! Here is a table in markdown format listing the shirts with sun protection along with a summarized description for each:\n\n| Shirt Name                                | Description                                                                                                                                                                                                         |\n|-------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Men's Tropical Plaid Short-Sleeve Shirt   | Made of 100% polyester, this shirt offers UPF 50+ protection, blocking 98% of the sun's harmful rays. It has front and back venting, two front bellows pockets, and is wrinkle-resistant.                                 |\n| Men's Plaid Tropic Shirt, Short-Sleeve    | This shirt is made of 52% polyester and 48% nylon, providing UPF 50+ protection. It features front and back cape venting, two front bellows pockets, and is wrinkle-free with quick perspiration evaporation.           |\n| Men's TropicVibe Shirt, Short-Sleeve      | With a shell of 71% nylon and 29% polyester, this shirt offers UPF 50+ protection. It is wrinkle-resistant, has front and back cape venting, two front bellows pockets, and is machine washable and dryable.        |\n| Sun Shield Shirt                          | This shirt is made of 78% nylon and 22% Lycra Xtra Life fiber, providing UPF 50+ protection. It is quick-drying, abrasion-resistant, fits comfortably over swimsuits, and is recommended by The Skin Cancer Foundation.   |\n\nEach shirt provides UPF 50+ sun protection, blocks 98% of harmful UV rays, and offers additional features like wrinkle-resistance, venting, and quick-drying comfort."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = index.query(query, llm=llm)"
      ],
      "metadata": {
        "id": "xizE9w8a-Zm7"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorstoreIndexCreator(\n",
        "    vectorstore_cls=DocArrayInMemorySearch,\n",
        "    embedding=embeddings,\n",
        ").from_loaders([loader])"
      ],
      "metadata": {
        "id": "8TOPrnpf-fJR"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBzNB7mm-n4Q",
        "outputId": "003fa2f4-9b0b-41fe-af46-584f2e2d6dd9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreIndexWrapper(vectorstore=<langchain_community.vectorstores.docarray.in_memory.DocArrayInMemorySearch object at 0x785bef1710d0>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain Types\n",
        "### 1. **\"stuff\"**:\n",
        "Retrieves the top k documents, concatenates all of them (plus the question) into a single prompt, and sends that in one go to the LLM.\n",
        "```python\n",
        "from langchain.chains import RetrievalQA\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        ")\n",
        "# Under the hood it does:\n",
        "# prompt = f\"Context: {doc1}\\n{doc2}\\n... Question: {query}\"\n",
        "# llm.invoke(prompt)\n",
        "```\n",
        " - Pro:\n",
        "    - Simplicity: only one LLM call.\n",
        "    - Low orchestration overhead: easiest to debug and monitor.\n",
        "    - Cost-effective when your total context fits comfortably under token limits.\n",
        " - Cons:\n",
        "    - Token limits: can easily exceed model context window if you retrieve many or large docs.\n",
        "    - No parallelism: single call, so you can’t leverage batching or map/reduce.\n",
        " - Best for:\n",
        "    - Small knowledge bases (e.g. < 2 KB total).\n",
        "    - Quick prototypes where ease of implementation outweighs scale concerns.\n",
        "    - Low-latency scenarios where one LLM call is preferable.\n",
        "\n",
        "### 2. **\"map_reduce\"**\n",
        "**Map step**: for each retrieved doc, call the LLM separately with a “map prompt” (question + single chunk) to produce a partial answer.\n",
        "\n",
        "**Reduce step**: concatenate all partial answers into one “combine prompt” and call the LLM again to synthesize a final answer.\n",
        "\n",
        "```python\n",
        "# Define the “map” prompt: run once per document chunk\n",
        "map_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"context\"],\n",
        "    template=(\n",
        "        \"You are an expert assistant.  Use ONLY the information in the provided context to answer the question.\\n\\n\"\n",
        "        \"Question: {question}\\n\\n\"\n",
        "        \"Context:\\n\"\n",
        "        \"{context}\\n\\n\"\n",
        "        \"Provide a concise answer (1–2 sentences).\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Define the “combine” prompt: run once over all partial answers\n",
        "combine_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"answers\"],\n",
        "    template=(\n",
        "        \"You are an expert assistant.  The user asked:\\n\\n\"\n",
        "        \"{question}\\n\\n\"\n",
        "        \"You have been given several partial answers, each based on different sources:\\n\\n\"\n",
        "        \"{answers}\\n\\n\"\n",
        "        \"Synthesize these into one final, comprehensive answer.  \"\n",
        "        \"Do not introduce new information—only use what’s in the partial answers.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"map_reduce\",\n",
        "    retriever=retriever,\n",
        "    chain_type_kwargs={\n",
        "      \"map_prompt\":    map_prompt,\n",
        "      \"combine_prompt\": combine_prompt,\n",
        "    },\n",
        ")\n",
        "```\n",
        " - Pros:\n",
        "    - Handles large corpora: each chunk is processed individually so you never blow past context limits.\n",
        "    - Parallelizable: the map calls can be issued in parallel.\n",
        "    - Fine-grained control: you can customize both map and reduce prompts independently.\n",
        " - Cons\n",
        "    - Two calls per chunk + one combine call: higher latency and cost.\n",
        "    - Complexity: need to manage two prompt templates and ensure consistency.\n",
        " - Best for\n",
        "    - Large documents split into many chunks (e.g. books, long reports).\n",
        "    - High-throughput scenarios where you can parallelize the map phase.\n",
        "    - Use cases requiring both local chunk reasoning and global synthesis.\n",
        "\n",
        "\n",
        "### 3. **\"refine\"**\n",
        "**Initial draft**: run a first pass on the entire (or partial) context to get a draft answer.\n",
        "\n",
        "**Refinement passes**: iteratively feed additional documents (or the same ones) plus the current draft back to the LLM to refine the answer.\n",
        "\n",
        "```python\n",
        "# INITIAL PROMPT: run on the first chunk → create the first draft\n",
        "initial_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"context\"],\n",
        "    template=(\n",
        "        \"You are an expert assistant.  Answer the user’s question using ONLY the provided context.\\n\\n\"\n",
        "        \"Question: {question}\\n\\n\"\n",
        "        \"Context:\\n\"\n",
        "        \"{context}\\n\\n\"\n",
        "        \"===\\n\"\n",
        "        \"Give a complete, concise answer in one or two paragraphs.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# REFINE PROMPT: run for each subsequent chunk → refine the draft\n",
        "refine_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"existing_answer\", \"context\"],\n",
        "    template=(\n",
        "        \"You are an expert assistant.  The user asked:\\n\\n\"\n",
        "        \"{question}\\n\\n\"\n",
        "        \"We already have this draft answer:\\n\\n\"\n",
        "        \"{existing_answer}\\n\\n\"\n",
        "        \"Here is an additional piece of context:\\n\\n\"\n",
        "        \"{context}\\n\\n\"\n",
        "        \"===\\n\"\n",
        "        \"Please update or expand the draft answer to incorporate any new relevant information from this context. \"\n",
        "        \"Do NOT remove any correct information from the existing answer, and do NOT introduce anything not supported by the context.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"refine\",\n",
        "    retriever=retriever,\n",
        "    chain_type_kwargs={\n",
        "      \"initial_prompt\": initial_prompt,\n",
        "      \"refine_prompt\":  refine_prompt,\n",
        "    },\n",
        ")\n",
        "```\n",
        " - Pros\n",
        "    - Progressive improvement: drafts get more detailed or accurate with each pass.\n",
        "    - Context control: you can decide how many docs to use per refine iteration.\n",
        "    - Better quality for complex questions that benefit from iterative context injection.\n",
        "\n",
        " - Cons\n",
        "    - Multiple sequential calls: slower than “map_reduce” if you do many refinements.\n",
        "    - Prompt engineering: you need at least two well-tuned prompts (initial vs refine).\n",
        "\n",
        " - Best for\n",
        "    - Deep reasoning tasks where initial answers need targeted correction or expansion.\n",
        "    - Conversational or interactive flows where you can refine based on user feedback.\n",
        "    - Medium-sized corpora (e.g. 5–10 chunks) where you want iterative focus rather than full map/reduce.\n",
        "\n",
        "### 4. **\"map_rerank\"**\n",
        "**Map**: like “map_reduce,” generate a candidate answer for each chunk.\n",
        "\n",
        "**Rerank**: score or rerank these per-chunk answers by calling the LLM again with a “rerank prompt” that compares them and picks the best.\n",
        "```python\n",
        "# MAP PROMPT: generate one candidate answer per chunk\n",
        "map_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"context\"],\n",
        "    template=(\n",
        "        \"You are a helpful assistant.  Answer the user’s question using ONLY the information below.\\n\\n\"\n",
        "        \"Question: {question}\\n\\n\"\n",
        "        \"Context:\\n\"\n",
        "        \"{context}\\n\\n\"\n",
        "        \"===\\n\"\n",
        "        \"Provide a concise answer (one or two sentences).\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# RERANK PROMPT: choose the single best candidate\n",
        "rerank_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"candidates\"],\n",
        "    template=(\n",
        "        \"You are an expert assistant tasked with selecting the best answer to the user’s question.\\n\\n\"\n",
        "        \"Question: {question}\\n\\n\"\n",
        "        \"Here are several candidate answers submitted by different context chunks:\\n\\n\"\n",
        "        \"{candidates}\\n\\n\"\n",
        "        \"===\\n\"\n",
        "        \"Review each candidate and reply with ONLY the number of the candidate that best and most completely answers the question.  \"\n",
        "        \"If multiple are equally good, pick the one that is most concise.\"\n",
        "    )\n",
        ")\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"map_rerank\",\n",
        "    retriever=retriever,\n",
        "    chain_type_kwargs={\n",
        "      \"map_prompt\":    map_prompt,\n",
        "      \"rerank_prompt\": rerank_prompt,\n",
        "    },\n",
        ")\n",
        "```\n",
        " - Pros\n",
        "    - Best-of-N selection: you get the single strongest candidate instead of a synthesized merge.\n",
        "    - Reduced hallucination: by comparing explicit answers rather than merging potentially conflicting info.\n",
        "\n",
        " - Cons\n",
        "    - N+1 calls: one map call per doc + one rerank call.\n",
        "    - Candidate loss: doesn’t produce a cohesive final answer—just picks one chunk’s response.\n",
        "\n",
        " - Best for\n",
        "    - Factoid QA where one chunk likely contains the correct answer (e.g. definition lookup).\n",
        "    - Ensemble scenarios where you want the model to choose the best chunk-level answer.\n",
        "    - Token-sensitive cases where merging would inflate context unnecessarily."
      ],
      "metadata": {
        "id": "zL3rQyhI_ZQe"
      }
    }
  ]
}